---
title: "RWorksheet5_(Celestra, Caneso, Arenal)"
output: pdf_document
date: "2024-11-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**[EXTRACTING TV SHOWS REVIEWS]**
```{r}
```
**1.**
```{r}
```
**________________________________________________________**
**Libraries**
```{r}
library(rvest)
library(httr)
library(polite)
library(dplyr)
library(stringr)
library(knitr) 
```

*IMDB URL*
```{r}
polite::use_manners(save_as = 'polite_scrape.R')

url <- "https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250"

session <- bow(url,
user_agent = "Educational")
session

```

*Title List*
```{r}
title_list <- scrape(session) %>%
html_nodes('h3.ipc-title__text') %>%
html_text

title_list_sub <- as.data.frame(title_list[2:26])
title_list_sub
```

*Split*
```{r}
colnames(title_list_sub) <- "ranks"

split_df <- strsplit(as.character(title_list_sub$ranks),".",fixed = T)
split_df <- data.frame(do.call(rbind,split_df))

colnames(split_df) <- c("ranks", "titles")
split_df
```

*Rating*
```{r}
rating_list <- scrape(session) %>%
html_nodes('span.ipc-rating-star--rating') %>%
html_text

```

*Number of People who voted*
```{r}
people_list <- scrape(session) %>%
html_nodes('span.ipc-rating-star--voteCount') %>%
html_text

```

*Episode and Year it was released*
```{r}
episode_list <- scrape(session) %>%
html_nodes('span.sc-5bc66c50-6.OOdsw.cli-title-metadata-item:nth-of-type(2)') %>%
html_text

year_list <- scrape(session) %>%
html_nodes('span.sc-5bc66c50-6.OOdsw.cli-title-metadata-item:nth-of-type(1)') %>%
html_text

```

**User Reviews, Critic Reviews, and Popularity Rating**
```{r}
home_link <- 'https://www.imdb.com/chart/toptv/'
main_page <- read_html(home_link)

links <- main_page %>%
  html_nodes("a.ipc-title-link-wrapper") %>%
  html_attr("href")

# Loop to get link of each show's page
show_data <- lapply(links, function(link) {
  complete_link <- paste0("https://imdb.com", link)
  
  #loop to get the link for user review page
  usrv_link <- read_html(complete_link)
  usrv_link_page <- usrv_link %>%
    html_nodes('a.isReview') %>%
    html_attr("href")
  
  #loop to get user reviews of each shows
  usrv <- read_html(paste0("https://imdb.com", usrv_link_page[1]))
  usrv_count <- usrv %>%
    html_nodes('[data-testid="tturv-total-reviews"]') %>%
    html_text()
  
  #loop to extract critic reviews
  critic <- usrv_link %>%
              html_nodes("span.score") %>%
              html_text()
  critic_df <- data.frame(Critic_Reviews = critic[2], stringsAsFactors = FALSE)
  
  #loop to extract pop rating
  pop_rating <- usrv_link %>%
              html_nodes('[data-testid="hero-rating-bar__popularity__score"]') %>%
              html_text()
  pop_rating_df <- data.frame(Popularity_Rating = pop_rating[2], stringsAsFactors = FALSE)
  
  return(data.frame(User_Reviews = usrv_count, Critic = critic_df, pop = pop_rating_df)) 
})

showss <- do.call(rbind, show_data)
```

**FINAL DATA**
```{r}
tv_shows <- data.frame(Ranking = split_df$ranks,
                       TV_Show_Title = split_df$titles,
                       Episodes = episode_list[1:25],
                       Release_Year = year_list[1:25],
                       Rating = rating_list[1:25],
                       No._of_Voter = people_list[1:25],
                       User_Review = showss$User_Reviews,
                       Popularity = showss$Popularity_Rating,
                       Critic_Reviews = showss$Critic_Reviews)
tv_shows
```
**________________________________________________________**
```{r}
#just for space
```

**2. Top 5 TV Shows**
```{r}


urls <- c("https://www.imdb.com/title/tt0903747/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt5491994/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt0795176/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt0185906/reviews/?ref_=tt_urv_sm",
          "https://www.imdb.com/title/tt7366338/reviews/?ref_=tt_urv_sm")

df <- list()

for(i in seq_along(urls)){
  
  sessions <- bow(urls[i], user_agent = "Educational")

#User name
userName <- scrape(sessions) %>%
html_nodes('a.ipc-link.ipc-link--base') %>%
html_text() %>%
  head(20)

#Date reviewed
dateReview <- scrape(sessions) %>%
html_nodes('li.ipc-inline-list__item.review-date') %>%
html_text() %>%
  head(20)

#User rating
userRating <- scrape(sessions) %>%
html_nodes('span.ipc-rating-star--rating') %>%
html_text() %>%
  head(20)

#Title of the review
reviewTitle <- scrape(sessions) %>%
html_nodes('h3.ipc-title__text') %>%
html_text() %>%
  head(20)

#Helpful
helpful <- scrape(sessions) %>%
html_nodes('span.ipc-voting__label') %>%
html_text()

#Unhelpful
unhelpful <- scrape(sessions) %>%
html_nodes('span.ipc-voting__label__count.ipc-voting__label__count--down') %>%
html_text() 

#Data frame for the user reviews.
userReviews <- data.frame(user_Name = userName[1:20],
                          Date_Reviewed = dateReview[1:20],
                          user_Rating = userRating[1:20],
                          Review_Title = reviewTitle[1:20],
                          Helpful = helpful[1:20],
                          Unhelpful = unhelpful[1:20],
                          stringsAsFactors = F)

df[[i]] <- userReviews
}

df[[1]]
df[[2]]
df[[3]]
df[[4]]
df[[5]]
```
**________________________________________________________**
```{r}
#just for space
```

**3.**
```{r}
library(ggplot2)
years <- substr(year_list, 1,4)
years <- as.numeric(years)      

ggplot(data.frame(Year = years), aes(x = Year)) +
  geom_line(stat = "count", fill = "skyblue", color = "blue") +
  labs(title = "Number of TV Shows Released by Year",
       x = "Year",
       y = "Number of TV Shows") +
  theme_minimal()

most_shows_year <- as.data.frame(table(years))
most_shows_year <- most_shows_year[which.max(most_shows_year$Freq), ]
print(most_shows_year)

```





**_______________________________________________________________________________________________**
```{r}
#just for space
```


**[EXTRACTING AMAZON PRODUCT REVIEWS]**
```{r}
#just for space
```

**Graphics Card**
```{r}

  gc_url <- c("https://www.amazon.com/s?k=graphics+card&crid=6809YKENO5VZ&sprefix=graphics+%2Caps%2C516&ref=nb_sb_ss_ts-doa-p_1_9",
            "https://www.amazon.com/s?k=graphics+card&page=2&crid=NY6LX0H811DR&qid=1732062550&sprefix=%2Caps%2C1816&ref=sr_pg_2")

graphics <- list()

for(i in seq_along(gc_url)){
  Sys.sleep(2)
  gSession <- bow(gc_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
 ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  card <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions[1:15],
    stringsAsFactors = FALSE
  )
  
graphics[[i]] <- card
}
```
```{r}
Gcard <- rbind(graphics[[1]], graphics[[2]])

kable(Gcard, caption = "Graphics Card Category")
```
```{r}
write.csv(Gcard, "Gcard.csv", row.names = F)
```


**Laptop**
```{r}
lap_url <- c("https://www.amazon.com/s?k=laptop&crid=15FICF43OPKJ2&sprefix=laptop%2Caps%2C1359&ref=nb_sb_ss_ts-doa-p_1_6",
            "https://www.amazon.com/s?k=laptop&page=2&crid=15FICF43OPKJ2&qid=1732065167&sprefix=laptop%2Caps%2C1359&ref=sr_pg_2")

laptop <- list()

for(i in seq_along(lap_url)){
  
  gSession <- bow(lap_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  lappy <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions[1:15],
    stringsAsFactors = FALSE
  )
  
laptop[[i]] <- lappy
}
```
```{r}
laptops <- rbind(laptop[[1]], laptop[[2]])

kable(laptops, caption = "Laptop Category")
```
```{r}
write.csv(laptops, "Laptop.csv", row.names = F)
```


**PC Case**
```{r}

pc_url <- c("https://www.amazon.com/s?k=pc+cases&crid=3232B9XX8J30L&sprefix=pccase%2Caps%2C674&ref=nb_sb_ss_ts-doa-p_3_6",
            "https://www.amazon.com/s?k=pc+cases&page=2&crid=3232B9XX8J30L&qid=1732066185&sprefix=pccase%2Caps%2C674&ref=sr_pg_2")

case <- list()

for(i in seq_along(pc_url)){
  Sys.sleep(2)
  gSession <- bow(pc_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  pCase <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions[1:15],
    stringsAsFactors = FALSE
  )
  
case[[i]] <- pCase
}
```
```{r}
pcCase <- rbind(case[[1]], case[[2]])

kable(pcCase, caption = "PC Case Category")
```
```{r}
write.csv(pcCase, "PC_Case.csv", row.names = F)
```


**Monitors**
```{r}

monitor_url <- c("https://www.amazon.com/s?k=monitors&crid=UGL8HSJMO1RM&qid=1732067471&refresh=1&sprefix=monitors%2Caps%2C588&ref=sr_pg_1",
               "https://www.amazon.com/s?k=monitors&page=2&crid=UGL8HSJMO1RM&qid=1732067581&refresh=1&sprefix=monitors%2Caps%2C588&ref=sr_pg_2")

mon <- list()

for(i in seq_along(monitor_url)){
  Sys.sleep(2)
  gSession <- bow(monitor_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  moni <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions,
    stringsAsFactors = FALSE
  )
  
mon[[i]] <- moni
}
```
```{r}
mOnitor <- rbind(mon[[1]], mon[[2]])

kable(mOnitor, caption = "Monitor Category")
```
```{r}
write.csv(mOnitor, "Monitor.csv", row.names = F)
```


**CPU**
```{r}

cpu_url <- c("https://www.amazon.com/s?k=cpu&crid=3DBICI2YNNKHJ&sprefix=cpu%2Caps%2C768&ref=nb_sb_noss_1",
               "https://www.amazon.com/s?k=cpu&page=2&crid=3DBICI2YNNKHJ&qid=1732067707&sprefix=cpu%2Caps%2C768&ref=sr_pg_2")

processor <- list()

for(i in seq_along(cpu_url)){
  Sys.sleep(2)
  gSession <- bow(cpu_url[i], user_agent = "Educational")
  
  # Scrape data
  product_titles <- scrape(gSession) %>%
    html_nodes("span.a-text-normal") %>% 
    html_text() %>%
    head(30)
  product_titles <- product_titles[!grepl("Check each product page for other buying options", product_titles)]
  
  price <- scrape(gSession) %>% 
    html_nodes('.a-price .a-offscreen') %>% 
    html_text() %>%
    head(30)
  price <- as.numeric(str_extract(price, "\\d+\\.\\d"))
  
  ratings <- scrape(gSession) %>% 
    html_nodes('span.a-icon-alt') %>% 
    html_text() %>%
    head(30)
  ratings <- as.numeric(str_extract(ratings, "\\d+\\.\\d"))
  
  reviews <- scrape(gSession) %>%
    html_nodes('.s-link-style .s-underline-text') %>% 
    html_text() %>%
    head(30)
  
  descriptions <- scrape(gSession) %>%
    html_nodes('.a-row.a-size-base.a-color-secondary') %>% 
    html_text() %>%
    head(30)
  
  # Find the maximum length
  max_length <- max(
    length(product_titles), length(price), length(ratings),
    length(reviews), length(descriptions)
  )
  
  # Standardize all vectors to the same length
  length(product_titles) <- max_length
  length(price) <- max_length
  length(ratings) <- max_length
  length(reviews) <- max_length
  length(descriptions) <- max_length
  
  # Create a data frame
  process <- data.frame(
    ProductTitle = product_titles[1:15],
    Price = price[1:15],
    Ratings = ratings[1:15],
    Reviews = reviews[1:15],
    Description = descriptions,
    stringsAsFactors = FALSE
  )
  
processor[[i]] <- process
}
```
```{r}
proc <- rbind(processor[[1]], processor[[2]])

kable(proc, caption = "CPU Category")
```
```{r}
write.csv(proc, "CPU.csv", row.names = F)
```

```{r}

```

